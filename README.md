# ğŸ“„ RAG-Based PDF Interaction Chatbot

An end-to-end **Retrieval-Augmented Generation (RAG)** application that allows users to interact with PDF documents using natural language. The system retrieves relevant document context using **FAISS vector search** and generates accurate, grounded answers using **Google Gemini API**, significantly reducing hallucinations compared to standalone LLMs.

---

## ğŸš€ Features

* ğŸ“‘ Upload and query PDF documents
* ğŸ” Semantic search using embeddings + FAISS
* ğŸ¤– Context-aware responses powered by Google Gemini
* ğŸ§  Reduces hallucinations via retrieval grounding
* ğŸ”„ Supports multi-question workflows
* âš¡ Fast local vector search

---

## ğŸ—ï¸ System Architecture

1. **PDF Ingestion** â€“ Upload and extract text from PDF files
2. **Text Chunking** â€“ Split large text into smaller, meaningful chunks
3. **Embedding Generation** â€“ Convert chunks into dense vector embeddings
4. **Vector Store (FAISS)** â€“ Store and index embeddings for similarity search
5. **Query Processing** â€“ Embed user query and retrieve top-k relevant chunks
6. **Answer Generation** â€“ Pass retrieved context + query to Gemini LLM

> "Retrieve first, then generate" â€“ ensures factual, document-grounded responses.

---

## ğŸ§° Tech Stack

* **Language:** Python
* **LLM:** Google Gemini API
* **Vector Database:** FAISS
* **Embeddings:** Gemini / compatible embedding model
* **Libraries:** LangChain, PyPDF, NumPy
* **Environment:** Python 3.9+

---

## ğŸ“ Project Structure

```
RAG_LLM/
â”‚â”€â”€ chatpdf1.py        # Main application logic
â”‚â”€â”€ requirements.txt  # Project dependencies
â”‚â”€â”€ .env               # API keys and environment variables
â”‚â”€â”€ README.md          # Project documentation
```

---

## âš™ï¸ Installation & Setup

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/Harishmaheshkumar/RAG_LLM.git
cd RAG_LLM
```

### 2ï¸âƒ£ Create Virtual Environment

```bash
python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Configure Environment Variables

Create a `.env` file:

```
GOOGLE_API_KEY=your_gemini_api_key
```

---

## â–¶ï¸ How to Run

```bash
python chatpdf1.py
```

* Upload a PDF
* Ask questions in natural language
* Get accurate, context-aware answers

---

## ğŸ§  Why RAG?

* âŒ LLM-only systems hallucinate
* âŒ Cannot access private documents
* âŒ Token limitations

âœ… RAG solves these by grounding responses in retrieved document context.

---

## ğŸ“Š Evaluation

* Manual qualitative testing with real user queries
* Compared LLM-only vs RAG-based answers
* Observed improved factual accuracy and reduced hallucinations

---

## âš ï¸ Limitations

* Performance depends on PDF text quality
* Scanned PDFs require OCR
* Large PDFs increase indexing time
* Stateless conversations (no long-term memory)

---

## ğŸ”® Future Enhancements

* Add OCR support for scanned PDFs
* Implement hybrid search (BM25 + embeddings)
* Add persistent vector databases (Pinecone / Weaviate)
* Enable multi-document querying
* Dockerize for deployment

---

## ğŸ‘¨â€ğŸ’» Author

**Harish M**
AI & ML Enthusiast | Data Science | Generative AI

* ğŸ”— GitHub: [https://github.com/Harishmaheshkumar](https://github.com/Harishmaheshkumar)
* ğŸ”— LinkedIn: [https://www.linkedin.com/in/harish-maheshkumar](https://www.linkedin.com/in/harish-maheshkumar)

---

â­ If you like this project, give it a star!
